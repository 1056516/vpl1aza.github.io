<link rel="icon" type="image/png" href="https://vplaza.org/favicons/VAI.png">

<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>V-oiceðŸ‘‹</title>
    <!-- Font Awesome for icons -->
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css">
    <!-- Google Fonts - Poppins -->
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Poppins:wght@400;500;600;700&display=swap" rel="stylesheet">
    <style>
        :root {
            --primary-blue: #0066ff;
            --dark-bg: #0b0b12;
            --darker-bg: #070710;
            --glow-blue: #00ccff;
            --light-blue: #e6f2ff;
            --gradient-start: #0033cc;
            --gradient-end: #0099ff;
            --discord-color: #5865F2;
        }

        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
            font-family: 'Poppins', sans-serif;
        }

        body {
            background-color: var(--dark-bg);
            color: white;
            height: 100vh;
            display: flex;
            justify-content: center;
            align-items: center;
            overflow: hidden;
            position: relative;
        }

        .app-container {
            width: 100%;
            height: 100vh;
            display: flex;
            flex-direction: column;
            justify-content: center;
            align-items: center;
            position: relative;
            overflow: hidden;
            z-index: 1;
        }

        .background-effect {
            position: absolute;
            width: 120%;
            height: 120%;
            background: radial-gradient(circle at center, rgba(0, 102, 255, 0.05) 0%, rgba(0, 0, 0, 0) 70%);
            z-index: -1;
            top: 50%;
            left: 50%;
            transform: translate(-50%, -50%);
            pointer-events: none;
        }

        .background-image {
            position: absolute;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
            object-fit: cover;
            opacity: 0.3;
            z-index: -2;
            filter: blur(5px); /* Add blur effect */
        }

        .orb {
            position: absolute;
            width: 300px;
            height: 300px;
            border-radius: 50%;
            top: 50%;
            left: 50%;
            transform: translate(-50%, -50%);
            overflow: hidden;
            display: flex;
            justify-content: center;
            align-items: center;
            box-shadow: 0 0 50px rgba(120, 80, 190, 0.3);
        }

        .orb-inner {
            position: relative;
            width: 100%;
            height: 100%;
            border-radius: 50%;
            overflow: hidden;
            /* Remove the float animation */
        }

        .orb-content {
            position: relative;
            width: 100%;
            height: 100%;
            border-radius: 50%;
            overflow: hidden;
            box-shadow: 0 0 100px rgba(0, 153, 255, 0.3);
            background: linear-gradient(135deg, #371b58, #4c3a88, #3a88c8, #2a6fc8);
            background-size: 400% 400%;
            animation: gradientShift 8s ease infinite;
        }

        .orb-glow {
            position: absolute;
            width: 100%;
            height: 100%;
            border-radius: 50%;
            box-shadow: inset 0 0 30px rgba(0, 153, 255, 0.2); /* Reduced from 0.4 */
            opacity: 0.4; /* Reduced from 0.6 */
            z-index: 1;
            transition: all 0.5s ease;
            animation: glowPulse 3s infinite alternate;
        }

        .orb-glow.active {
            opacity: 0.6; /* Reduced from 0.85 */
        }

        .wave-container {
            position: absolute;
            width: 100%;
            height: 100%;
            display: flex;
            justify-content: center;
            align-items: center;
            opacity: 0;
            transition: opacity 0.5s ease;
        }

        .wave-container.active {
            opacity: 1;
        }

        .sound-wave {
            position: absolute;
            top: 50%;
            left: 50%;
            transform: translate(-50%, -50%);
            width: 70%;
            height: 40px;
            display: flex;
            justify-content: center;
            align-items: center;
            gap: 5px;
            opacity: 0;
            transition: opacity 0.3s ease;
        }

        .sound-wave.active {
            opacity: 1;
            animation: waveFormDistort 2s infinite alternate;
        }

        .sound-wave.ai-speaking {
            transform: translate(-50%, -50%) scale(1.05);
        }

        .wave-bar {
            width: 4px;
            background-color: #8f5ddb; /* Changed from var(--primary-blue) to purple */
            border-radius: 2px;
            animation: waveAnimation 1.2s infinite ease-in-out;
            box-shadow: 0 0 8px rgba(143, 93, 219, 0.7); /* Changed from blue to purple glow */
        }

        .wave-bar:nth-child(1) { animation-delay: 0.0s; height: 10px; }
        .wave-bar:nth-child(2) { animation-delay: 0.1s; height: 15px; }
        .wave-bar:nth-child(3) { animation-delay: 0.2s; height: 20px; }
        .wave-bar:nth-child(4) { animation-delay: 0.3s; height: 30px; }
        .wave-bar:nth-child(5) { animation-delay: 0.4s; height: 20px; }
        .wave-bar:nth-child(6) { animation-delay: 0.3s; height: 15px; }
        .wave-bar:nth-child(7) { animation-delay: 0.2s; height: 10px; }

        .controls-container {
            position: fixed;
            bottom: 20px;
            left: 20px;
            display: flex;
            gap: 10px;
        }

        .mic-button {
            width: 50px;
            height: 50px;
            border-radius: 50%;
            background: linear-gradient(135deg, #8f5ddb, #7b4cbc);
            border: none;
            display: flex;
            justify-content: center;
            align-items: center;
            cursor: pointer;
            position: relative;
            box-shadow: 0 0 20px rgba(143, 93, 219, 0.5);
            transition: all 0.3s ease;
        }

        /* Add styles for mic-button locked/unlocked states */
        .mic-button.locked {
            background: linear-gradient(135deg, #d43838, #9e2929);
            box-shadow: 0 0 20px rgba(212, 56, 56, 0.5);
        }

        .mic-button.unlocked {
            background: linear-gradient(135deg, #8f5ddb, #7b4cbc);
            box-shadow: 0 0 20px rgba(143, 93, 219, 0.5);
        }

        .delete-button {
            width: 50px;
            height: 50px;
            border-radius: 50%;
            background: linear-gradient(135deg, #5c5c5c, #3a3a3a);
            border: none;
            display: flex;
            justify-content: center;
            align-items: center;
            cursor: pointer;
            position: relative;
            box-shadow: 0 0 20px rgba(60, 60, 60, 0.5);
            transition: all 0.3s ease;
        }

        .mic-button:hover:not(:disabled), .delete-button:hover {
            transform: scale(1.05);
        }

        .mic-button:disabled {
            opacity: 0.5;
            cursor: not-allowed;
            animation: none;
        }

        .mic-button i, .delete-button i {
            font-size: 24px;
            color: white;
        }

        .status-text {
            font-size: 1.2rem;
            font-weight: 600;
            margin-top: 20px;
            color: white;
            opacity: 0.9;
            letter-spacing: 0.5px;
            text-align: center;
            min-height: 28px;
            display: none; /* Hide status text */
        }

        .delete-chat-btn {
            display: none; /* Hide the original delete button */
        }

        /* Animations */
        @keyframes pulse {
            0% {
                opacity: 0.7;
                transform: scale(0.95);
            }
            70% {
                opacity: 0;
                transform: scale(1.3);
            }
            100% {
                opacity: 0;
                transform: scale(1.5);
            }
        }

        @keyframes waveAnimation {
            0%, 100% {
                transform: scaleY(0.3);
                background-color: #8f5ddb; /* Purple color at start/end */
            }
            50% {
                transform: scaleY(1);
                background-color: #000000; /* Black color at peak */
            }
        }

        @keyframes pulseButton {
            0% {
                transform: scale(1);
                box-shadow: 0 0 20px rgba(143, 93, 219, 0.5);
            }
            50% {
                transform: scale(1.05);
                box-shadow: 0 0 30px rgba(143, 93, 219, 0.7);
            }
            100% {
                transform: scale(1);
                box-shadow: 0 0 20px rgba(143, 93, 219, 0.5);
            }
        }

        @keyframes waveFormDistort {
            0% {
                transform: perspective(200px) rotateX(0deg) scale(1);
            }
            50% {
                transform: perspective(200px) rotateX(5deg) scale(1.05);
            }
            100% {
                transform: perspective(200px) rotateX(-5deg) scale(1.1);
            }
        }

        /* Media Queries */
        @media (max-width: 768px) {
            .orb {
                width: 220px;
                height: 220px;
            }
        }

        @keyframes glowPulse {
            0% {
                box-shadow: inset 0 0 20px rgba(69, 39, 160, 0.2), 0 0 10px rgba(69, 39, 160, 0.1); /* Reduced intensity */
            }
            100% {
                box-shadow: inset 0 0 30px rgba(0, 153, 255, 0.3), 0 0 20px rgba(0, 153, 255, 0.1); /* Reduced intensity */
            }
        }

        @keyframes gradientShift {
            0% {
                background-position: 0% 50%;
            }
            50% {
                background-position: 100% 50%;
            }
            100% {
                background-position: 0% 50%;
            }
        }

        @keyframes float {
            0%, 100% {
                transform: translateY(0);
            }
            50% {
                transform: translateY(-15px);
            }
        }

        .check-animation {
            position: absolute;
            width: 80%; /* Increased from 70% to fill more of the orb */
            height: 80%; /* Increased from 70% to fill more of the orb */
            object-fit: contain;
            top: 50%;
            left: 50%;
            transform: translate(-50%, -50%);
            z-index: 5;
            opacity: 0;
            transition: opacity 0.3s ease;
            pointer-events: none;
        }

        .check-animation.active {
            opacity: 1;
        }
    </style>
</head>
<body>
    <div class="app-container">
        <div class="background-effect"></div>
        <img src="/bg.jpg" class="background-image" alt="Background" id="background-image">

        <div class="orb">
            <div class="orb-inner">
                <div class="orb-content">
                    <div class="orb-glow"></div>
                    <div class="wave-container">
                        <div class="wave-circle"></div>
                        <div class="wave-circle"></div>
                        <div class="wave-circle"></div>
                    </div>
                    <div class="sound-wave">
                        <div class="wave-bar"></div>
                        <div class="wave-bar"></div>
                        <div class="wave-bar"></div>
                        <div class="wave-bar"></div>
                        <div class="wave-bar"></div>
                        <div class="wave-bar"></div>
                        <div class="wave-bar"></div>
                    </div>
                    <img src="/assets/check.gif" class="check-animation" id="check-animation" alt="Check animation">
                </div>
            </div>
        </div>

        <div class="status-text">Tap microphone to talk</div>
        <div class="controls-container">
            <button class="mic-button" id="mic-button">
                <i class="fas fa-microphone"></i>
            </button>
            <button class="delete-button" id="delete-button">
                <i class="fas fa-trash-alt"></i>
            </button>
        </div>
    </div>

    <script>
        // Configuration
        const CONFIG = {
            apiKey: "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",
            model: "llama3-8b-8192",
            apiEndpoint: "https://api.groq.com/openai/v1/chat/completions",
            defaultGreeting: "Hello! How can I assist you today?",
            voiceID: "e8e5fffb-252c-436d-b842-8879b84445b6", // Cartesia's AI Voice Codey
            voiceEmbed: [-0.023989892, -0.08448649, 0.022031268, -0.07057139, 0.12223451, -0.029491369, 0.045303233, -0.011311343, 0.13188389, -0.016259475, 0.0046919156, -0.06912895, -0.10005153, -0.02191228, -0.09062025, 0.049770422, -0.053926792, -0.034793563, 0.046280753, 0.11103954, -0.054568704, 0.095876604, -0.061484158, -0.0875655, -0.08495131, 0.085307896, -0.100641645, -0.0012436107, 0.11817303, -0.037164245, -0.02990801, 0.016991355, 0.0015218591, 0.13920002, -0.019198101, -0.025688726, 0.041610297, -0.07351482, -0.036994908, -0.044812255, -0.035154916, -0.10578436, -0.065148085, -0.07112482, -0.16526894, 0.10494398, 0.11660931, 0.013476909, 0.07631803, 0.010208819, -0.051123552, 0.028208287, 0.024599375, -0.03864338, 0.0016316884, -0.05169146, -0.028076882, 0.024385704, 0.10735396, 0.10839656, 0.027845534, -0.0826449, -0.010290669, -0.008548923, -0.013661587, 0.061037697, 0.11423113, 0.006610708, 0.06287958, -0.10213754, -0.059306297, 0.14914681, 0.019782793, 0.056643162, 0.064816676, -0.10200007, -0.06365681, 0.12645498, 0.042626865, -0.02642232, -0.025649097, -0.011646276, -0.007965857, 0.06454265, 0.03266104, -0.053809416, 0.024273401, 0.11329707, 0.030302474, -0.00050120795, -0.07243864, -0.08599348, 0.038157098, 0.003464039, 0.13629903, -0.28741464, -0.0014421503, -0.14735115, 0.041660942, -0.054005496, 0.03740774, -0.053002954, -0.0752357, 0.048252273, -0.055931248, 0.03196891, -0.07858551, 0.04284852, -0.012976681, 0.014983372, 0.07826965, -0.042085744, -0.084927686, -0.027896233, 0.031068621, -0.00074405497, -0.014435404, -0.07833662, -0.082763, 0.060509756, 0.051797185, 0.037373513, -0.0902045, -0.03892902, -0.009162266, 0.0031911524, -0.05750676, -0.006241986, -0.026270388, -0.029814603, 0.046943713, -0.0080407765, -0.03210368, -0.028178234, 0.123207994, 0.047551144, 0.07950631, 0.019763911, 0.031892627, 0.08915652, 0.10601049, 0.08901922, -0.007866781, 0.019862816, -0.08856446, -0.04735954, -0.084398516, 0.089368686, 0.1527405, -0.022071263, 0.07413698, 0.022185814, 0.102057464, 0.08290962, -0.019248147, -0.007064097, -0.018397521, 0.022572413, -0.18511306, -0.067540735, 0.10665864, 0.036814064, 0.006329614, -0.06867632, 0.1916783, 0.031433817, 0.007089221, -0.028897751, -0.05296714, -0.060072105, -0.04238049, 0.019612296, -0.066136815, -0.03478029, -0.021567797, -0.10116889, 0.011895469, -0.07380574, 0.1828761, -0.15627074, 0.014369829, 0.05888959, -0.014544148, 0.074670225, 0.06708018, -0.02226682, 0.0072541055, 0.06080716, -0.009129852, -0.03880983, -0.06828793, -0.110845335]
        };

        // User Settings (will be stored in localStorage)
        let userSettings = JSON.parse(localStorage.getItem('userSettings')) || {
            wakeWord: '',
            useWakeWord: false,
            alarms: []
        };

        // DOM Elements
        const micButton = document.getElementById('mic-button');
        const statusText = document.querySelector('.status-text');
        const orbGlow = document.querySelector('.orb-glow');
        const waveContainer = document.querySelector('.wave-container');
        const soundWave = document.querySelector('.sound-wave');
        const checkAnimation = document.getElementById('check-animation');
        const deleteButton = document.getElementById('delete-button');
        const backgroundImage = document.getElementById('background-image');

        // App State
        let isListening = false;
        let isAISpeaking = false;
        let autoListenMode = true;
        let hasInitialMicPermission = false;
        let speechSynthesis = window.speechSynthesis;
        let recognition;
        let conversation = JSON.parse(localStorage.getItem('conversation')) || [];
        let activeAlarms = [];
        let micLocked = false; // New state to track if mic is locked/unlocked

        // Save user settings
        function saveUserSettings() {
            localStorage.setItem('userSettings', JSON.stringify(userSettings));
        }

        // Check and process alarms
        function checkAndProcessAlarms() {
            const now = new Date();
            const currentTime = now.getTime();

            userSettings.alarms.forEach((alarm, index) => {
                if (alarm.time <= currentTime && !alarm.triggered) {
                    // Trigger alarm
                    userSettings.alarms[index].triggered = true;
                    saveUserSettings();

                    // Pause any active speech or listening
                    if (isAISpeaking) {
                        speechSynthesis.cancel();
                    }
                    if (isListening) {
                        pauseListening();
                    }

                    // Notify the user
                    const alarmMessage = `Your alarm for ${alarm.label || 'Reminder'} is now.`;
                    synthesizeSpeech(alarmMessage);
                }
            });

            // Clean up old alarms (keep for 1 hour after triggering)
            userSettings.alarms = userSettings.alarms.filter(alarm => {
                return !(alarm.triggered && alarm.time < currentTime - 3600000);
            });
            saveUserSettings();

            // Check again in 5 seconds
            setTimeout(checkAndProcessAlarms, 5000);
        }

        // Process commands from user input
        function processCommands(text) {
            const lowerText = text.toLowerCase();
            let isCommand = false;

            // Check for "who made you" type questions
            if (lowerText.includes('who made you') ||
                lowerText.includes('who created you') ||
                lowerText.includes('who built you') ||
                lowerText.includes('who developed you') ||
                lowerText.includes('who designed you') ||
                lowerText.includes('who programmed you')) {
                isCommand = true;
                const creatorMessage = "The Vplaza Team has created me, a static, full stack ai MODAL who has a brain unlike you";
                synthesizeSpeech(creatorMessage);

                // Add to conversation history
                conversation.push({
                    role: 'assistant',
                    content: creatorMessage
                });
                localStorage.setItem('conversation', JSON.stringify(conversation));

                return isCommand;
            }

            // Set alarm command
            if (lowerText.includes('set alarm') || lowerText.includes('set a alarm') || lowerText.includes('set an alarm')) {
                isCommand = true;

                // Extract time information
                const timePattern = /\b(1[0-2]|0?[1-9]):([0-5][0-9])(?:\s*)?(am|pm)?\b|\b(1[0-2]|0?[1-9])(?:\s*)?(am|pm)\b|\b(1[0-2]|0?[1-9])\s+o'clock(?:\s*)?(am|pm)?\b/i;
                const timeMatch = text.match(timePattern);

                if (timeMatch) {
                    let hours, minutes = 0, period;

                    if (timeMatch[1] && timeMatch[2]) {
                        hours = parseInt(timeMatch[1]);
                        minutes = parseInt(timeMatch[2]);
                        period = timeMatch[3] ? timeMatch[3].toLowerCase() : null;
                    } else if (timeMatch[4]) {
                        hours = parseInt(timeMatch[4]);
                        period = timeMatch[5] ? timeMatch[5].toLowerCase() : null;
                    } else if (timeMatch[6]) {
                        hours = parseInt(timeMatch[6]);
                        period = timeMatch[7] ? timeMatch[7].toLowerCase() : null;
                    }

                    // Default to PM for hours 1-11 if no AM/PM specified
                    if (!period) {
                        const currentHour = new Date().getHours();
                        if (hours < 12 && currentHour >= 12) {
                            period = 'pm';
                        } else {
                            period = 'am';
                        }
                    }

                    // Convert to 24-hour format
                    if (period === 'pm' && hours < 12) {
                        hours += 12;
                    } else if (period === 'am' && hours === 12) {
                        hours = 0;
                    }

                    // Set the alarm time
                    const now = new Date();
                    let alarmTime = new Date(now.getFullYear(), now.getMonth(), now.getDate(), hours, minutes, 0);

                    // If the time is in the past, set it for tomorrow
                    if (alarmTime < now) {
                        alarmTime.setDate(alarmTime.getDate() + 1);
                    }

                    // Extract label if present
                    let label = "Alarm";
                    const labelMatch = text.match(/for\s+(.+?)(?:$|\.|\band\b)/i);
                    if (labelMatch && labelMatch[1]) {
                        label = labelMatch[1].trim();
                    }

                    // Add the alarm
                    userSettings.alarms.push({
                        time: alarmTime.getTime(),
                        label: label,
                        triggered: false
                    });
                    saveUserSettings();

                    // Confirmation message
                    const confirmationMessage = `Alarm set for ${hours % 12 || 12}:${minutes.toString().padStart(2, '0')} ${period.toUpperCase()} ${label !== "Alarm" ? `for ${label}` : ""}.`;
                    synthesizeSpeech(confirmationMessage);
                } else {
                    synthesizeSpeech("I couldn't understand the time for your alarm. Please specify a time like 3:30 PM.");
                }

                return isCommand;
            }

            // Set wake word command
            if (lowerText.includes('only answer to me when i say') || lowerText.includes('only respond when i say')) {
                isCommand = true;

                // Extract the wake word/phrase
                const wakeWordMatch = text.match(/(?:only answer to me when i say|only respond when i say)\s+(.+?)(?:$|\.)/i);
                if (wakeWordMatch && wakeWordMatch[1]) {
                    userSettings.wakeWord = wakeWordMatch[1].trim();
                    userSettings.useWakeWord = true;
                    saveUserSettings();

                    synthesizeSpeech(`Wake word set to "${userSettings.wakeWord}". I'll only respond when you say this first.`);
                } else {
                    synthesizeSpeech("I couldn't understand the wake word. Please try again with a clearer phrase.");
                }

                return isCommand;
            }

            // Disable wake word
            if (lowerText.includes('disable wake word') || lowerText.includes('turn off wake word')) {
                isCommand = true;
                userSettings.useWakeWord = false;
                saveUserSettings();

                synthesizeSpeech("Wake word disabled. I'll respond to all your queries now.");
                return isCommand;
            }

            // Change background image
            if (lowerText.includes('change background') || lowerText.includes('new background')) {
                isCommand = true;

                // Generate a random nature background from Unsplash
                const categories = ['nature', 'space', 'abstract', 'technology', 'landscape', 'cosmos'];
                const randomCategory = categories[Math.floor(Math.random() * categories.length)];
                const backgroundUrl = "/bg.jpg";

                backgroundImage.src = backgroundUrl;
                synthesizeSpeech(`Background changed to a ${randomCategory} theme.`);
                return isCommand;
            }

            return isCommand;
        }

        // Initialize Speech Recognition with better permission handling
        function initSpeechRecognition() {
            if (!('SpeechRecognition' in window) && !('webkitSpeechRecognition' in window)) {
                statusText.textContent = "Speech recognition not supported";
                micButton.disabled = true;
                return false;
            }

            try {
                recognition = new (window.SpeechRecognition || window.webkitSpeechRecognition)();

                // Request permission explicitly to avoid repeated prompts
                navigator.mediaDevices.getUserMedia({ audio: true })
                    .then(stream => {
                        // Stop the stream immediately - we just needed permission
                        stream.getTracks().forEach(track => track.stop());
                        hasInitialMicPermission = true;

                        // Configure recognition
                        setupRecognition();

                        // Start listening if auto mode and mic is not locked
                        if (autoListenMode && !micLocked) {
                            startListening();
                        }
                    })
                    .catch(err => {
                        console.error("Microphone permission denied:", err);
                        statusText.textContent = "Microphone access denied";
                        micButton.disabled = false;
                    });

                return true;
            } catch (error) {
                console.error("Error initializing speech recognition:", error);
                statusText.textContent = "Speech recognition error";
                micButton.disabled = true;
                return false;
            }
        }

        // Setup recognition configuration
        function setupRecognition() {
            recognition.continuous = true;
            recognition.interimResults = false;
            recognition.lang = 'en-US';

            recognition.onstart = () => {
                isListening = true;
                statusText.textContent = "Listening...";
                micButton.classList.add('listening');
                soundWave.classList.add('active');
                waveContainer.classList.add('active');
                orbGlow.classList.add('active');
            };

            recognition.onresult = (event) => {
                // If mic is locked, don't process any results
                if (micLocked) return;

                const resultIndex = event.resultIndex;
                const transcript = event.results[resultIndex][0].transcript;

                if (transcript.trim().length > 0) {
                    // If AI is speaking and the user speaks, interrupt the AI
                    if (isAISpeaking) {
                        console.log("Interrupting AI speech!");
                        // Cancel current speech
                        speechSynthesis.cancel();
                        isAISpeaking = false;
                        soundWave.classList.remove('ai-speaking');
                    }

                    // Check for wake word if enabled
                    if (userSettings.useWakeWord && userSettings.wakeWord) {
                        if (!transcript.toLowerCase().includes(userSettings.wakeWord.toLowerCase())) {
                            // Wake word not found, continue listening
                            return;
                        }
                    }

                    // Check if this is a command
                    if (processCommands(transcript)) {
                        // It was a command, no need to send to AI
                        return;
                    }

                    // Add to conversation memory
                    conversation.push({
                        role: 'user',
                        content: transcript
                    });
                    localStorage.setItem('conversation', JSON.stringify(conversation));

                    // Pause listening temporarily while processing
                    pauseListening();

                    // Send to AI API for processing
                    sendToAI(transcript);
                }
            };

            recognition.onend = () => {
                if (isListening) {
                    // If we still want to be listening but it ended for some reason,
                    // restart it (unless the mic is locked)
                    if (autoListenMode && !micLocked) {
                        setTimeout(() => {
                            startListening();
                        }, 100);
                    } else {
                        resetUIState();
                    }
                }
            };

            recognition.onerror = (event) => {
                console.error('Speech recognition error:', event.error);

                // Don't show error for aborted recognition (happens during normal operation)
                if (event.error !== 'aborted') {
                    statusText.textContent = "Error: " + event.error;
                }

                resetUIState();

                // If permission denied, update UI accordingly
                if (event.error === 'not-allowed' || event.error === 'permission-denied') {
                    hasInitialMicPermission = false;
                    statusText.textContent = "Microphone access denied";
                    micButton.disabled = false;
                } else if (autoListenMode && !isAISpeaking) {
                    // Try to restart listening if in auto mode
                    setTimeout(() => {
                        startListening();
                    }, 1000);
                }
            };
        }

        // Function to start listening
        function startListening() {
            // Only start if we're not already listening and not while AI is speaking
            if (!isListening && hasInitialMicPermission && !micLocked) {
                isListening = true;

                // Update UI to show listening state
                micButton.classList.add('listening');
                statusText.textContent = 'Listening...';
                orbGlow.classList.add('active');
                waveContainer.classList.add('active');
                soundWave.classList.add('active');

                try {
                    recognition.start();
                } catch (e) {
                    console.error('Recognition error:', e);
                    pauseListening();
                }
            }
        }

        // Pause listening
        function pauseListening() {
            if (isListening) {
                isListening = false;

                // Update UI to show not listening state
                micButton.classList.remove('listening');
                statusText.textContent = 'Tap microphone to talk';
                waveContainer.classList.remove('active');
                soundWave.classList.remove('active');

                try {
                    recognition.stop();
                } catch (e) {
                    console.error('Recognition stop error:', e);
                }
            }
        }

        // Reset UI state
        function resetUIState() {
            micButton.classList.remove('listening');
            statusText.textContent = 'Tap microphone to talk';
            orbGlow.classList.remove('active');
            waveContainer.classList.remove('active');
            soundWave.classList.remove('active');
            soundWave.classList.remove('ai-speaking');
        }

        // Mic Button Click Event - FIXED FOR LOCK/UNLOCK MIC
        micButton.addEventListener('click', () => {
            // Toggle mic lock
            micLocked = !micLocked;

            // Update button icon and classes based on lock state
            if (micLocked) {
                micButton.innerHTML = '<i class="fas fa-microphone-slash"></i>';
                micButton.classList.add('locked');
                micButton.classList.remove('unlocked');
                pauseListening();
                resetUIState();
                console.log("Microphone locked/muted");
            } else {
                micButton.innerHTML = '<i class="fas fa-microphone"></i>';
                micButton.classList.add('unlocked');
                micButton.classList.remove('locked');
                startListening();
                hasInitialMicPermission = true;
                console.log("Microphone unlocked/unmuted");
            }
        });

        // Delete Button Click Event
        deleteButton.addEventListener('click', () => {
            // Clear conversation
            conversation = [];
            localStorage.setItem('conversation', JSON.stringify(conversation));

            // Visual feedback
            statusText.textContent = "Chat history cleared";
            setTimeout(() => {
                statusText.textContent = "Tap microphone to talk";
            }, 2000);
        });

        // Function to send message to AI API
        async function sendToAI(message) {
            try {
                statusText.textContent = "Thinking...";

                // Prepare conversation history for API
                const messages = [...conversation];
                if (messages.length === 0 || messages[messages.length - 1].role !== 'user') {
                    messages.push({ role: 'user', content: message });
                }

                // Call Groq API for Llama 3
                const response = await fetch(CONFIG.apiEndpoint, {
                    method: 'POST',
                    headers: {
                        'Content-Type': 'application/json',
                        'Authorization': `Bearer ${CONFIG.apiKey}`
                    },
                    body: JSON.stringify({
                        model: CONFIG.model,
                        messages: messages,
                        max_tokens: 500,
                        temperature: 0.7
                    })
                });

                if (!response.ok) {
                    throw new Error(`API error: ${response.status}`);
                }

                const data = await response.json();
                processChatCompletion(data);

            } catch (error) {
                console.error('Error communicating with AI:', error);
                statusText.textContent = "Error communicating with AI";
                isAISpeaking = false;

                setTimeout(() => {
                    if (autoListenMode && hasInitialMicPermission) {
                        startListening();
                    } else {
                        statusText.textContent = "Tap microphone to talk";
                        micButton.disabled = false;
                    }
                }, 3000);
            }
        }

        // Function to process chat completion response
        async function processChatCompletion(completion) {
            // If we have a completion
            if (completion && completion.choices && completion.choices.length > 0) {
                // Extract the response text
                const responseText = completion.choices[0].message.content;

                // Hide sound wave when check animation shows
                soundWave.classList.remove('active');

                // Show check animation when response is received
                const checkAnimation = document.getElementById('check-animation');
                checkAnimation.classList.add('active');

                // Add to conversation history
                conversation.push({
                    role: 'assistant',
                    content: responseText
                });
                localStorage.setItem('conversation', JSON.stringify(conversation));

                // Speak the response
                synthesizeSpeech(responseText);

                // Remove the animation after 5 seconds
                setTimeout(() => {
                    checkAnimation.classList.remove('active');
                    // Only show sound wave again if AI is speaking and check animation is gone
                    if (isAISpeaking) {
                        soundWave.classList.add('active');
                    }
                }, 5000);
            }
        }

        // Function to synthesize speech
        function synthesizeSpeech(text) {
            isAISpeaking = true;
            statusText.textContent = "Speaking...";
            orbGlow.classList.add('active');

            // Only show sound wave if check animation isn't active
            if (!checkAnimation.classList.contains('active')) {
                soundWave.classList.add('active');
            }

            soundWave.classList.add('ai-speaking');

            // Cancel any existing speech before starting new speech
            if (speechSynthesis.speaking) {
                speechSynthesis.cancel();
            }

            // For demonstration, using browser's speech synthesis
            const utterance = new SpeechSynthesisUtterance();

            // Set initial values for more human-like speech
            utterance.rate = 0.95;  // Slightly slower rate for more natural speaking
            utterance.pitch = 1.1;  // Slightly higher pitch for clarity
            utterance.volume = 1.0;

            // The voices are loaded asynchronously
            let voices = speechSynthesis.getVoices();
            if (voices.length === 0) {
                speechSynthesis.onvoiceschanged = () => {
                    voices = speechSynthesis.getVoices();
                    setVoice();
                };
            } else {
                setVoice();
            }

            function setVoice() {
                // Try to find a nice male voice - prioritize natural-sounding voices
                const preferredVoices = [
                    'Google UK English Male',
                    'Microsoft David',
                    'Microsoft Mark',
                    'Microsoft Guy',
                    'Daniel',
                    'Alex'
                ];

                for (const preferredVoice of preferredVoices) {
                    const voice = voices.find(v => v.name.includes(preferredVoice));
                    if (voice) {
                        utterance.voice = voice;
                        break;
                    }
                }

                // If no preferred voice found, try to find any male voice
                if (!utterance.voice) {
                    const maleVoice = voices.find(v => v.name.toLowerCase().includes('male'));
                    if (maleVoice) {
                        utterance.voice = maleVoice;
                    }
                }

                // Apply human-like speech properties
                utterance.rate = 0.95;  // Slightly slower rate for more natural speaking
                utterance.pitch = 1.1;  // Slightly higher pitch for clarity

                // Add SSML-style breathing and pauses if supported
                const processedText = addNaturalPauses(text);
                utterance.text = processedText;

                utterance.onend = () => {
                    finishSpeaking();
                };

                utterance.onerror = () => {
                    console.error("Speech synthesis error");
                    finishSpeaking();
                };

                speechSynthesis.speak(utterance);
            }
        }

        // Function to clean up after speech is done
        function finishSpeaking() {
            isAISpeaking = false;
            statusText.textContent = "Listening...";
            soundWave.classList.remove('ai-speaking');

            // Auto start listening again if we have permission and mic isn't locked
            if (autoListenMode && hasInitialMicPermission && !micLocked) {
                startListening();
            } else {
                resetUIState();
            }
        }

        // Function to add natural pauses to speech for more human-like delivery
        function addNaturalPauses(text) {
            // Don't modify the original text for browsers that don't support advanced features
            // This is a simple way to add some natural rhythm without SSML

            // Add slight pauses after punctuation
            const sentences = text.split(/([.!?])/);
            let processedText = '';

            for (let i = 0; i < sentences.length; i++) {
                processedText += sentences[i];

                // If this is punctuation followed by more text, add a pause
                if (i % 2 === 1 && i < sentences.length - 1 && sentences[i+1].trim() !== '') {
                    processedText += ' '; // Add a space for a natural pause
                }
            }

            return processedText;
        }

        // Initialize with a welcome message
        window.addEventListener('load', () => {
            // Initialize the speech recognition
            initSpeechRecognition();

            // Initialize visual effects
            orbGlow.classList.add('active');

            // Set mic to unlocked state by default
            micLocked = false;
            micButton.innerHTML = '<i class="fas fa-microphone"></i>';
            micButton.classList.add('unlocked');
            micButton.classList.remove('locked');

            // If we have a conversation already, don't re-greet
            const needsGreeting = !conversation.length;

            if (needsGreeting) {
                setTimeout(() => {
                    synthesizeSpeech(CONFIG.defaultGreeting);

                    // Add initial message to conversation
                    conversation.push({
                        role: 'assistant',
                        content: CONFIG.defaultGreeting
                    });
                    localStorage.setItem('conversation', JSON.stringify(conversation));
                }, 1000);
            } else {
                // If we already have a conversation, start listening right away
                setTimeout(() => {
                    if (autoListenMode && !micLocked) {
                        startListening();
                    }
                }, 1000);
            }
        });
    </script>
</body>
</html>
